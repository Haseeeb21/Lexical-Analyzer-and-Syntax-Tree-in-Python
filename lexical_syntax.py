# -*- coding: utf-8 -*-
"""Lexical_Syntax.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CuhyIhYk9ASCz_sXngXloL0V-IAFgYrv
"""

import re     #Importing Regular Expression Library
import ast    #Importing Abstract Syntax Tree Library

      #Implementing Lexical Analyzer
      
def LexicalAnalyzer(exp):   #Func
  print("\nGiven Expression:", exp)   #Printing expression

          #Tokenization of expression

  tok = re.findall("[0-9a-z-(*+)/]", exp)     #Builtin findall func
                                                #to find in expression
                                                #and store in tok

  print("\nTags/Tokens of Expression:", tok)  #Printing the tokens

      #Implementing Syntax Tree

def SyntaxTree(exp):    #Func
  tree = ast.parse(exp, mode='eval')  #Parses the exp with eval mode

  print("\nEvaluation Answer:")
  print(eval(compile(tree, '', mode='eval')))  #Compiling

  print(ast.dump(tree))  #Returns formatted string

exp = input("Enter Expression: ")   #Taking expression input from user

            #Calling Functions
LexicalAnalyzer(exp)
SyntaxTree(exp)

import re
tokens = []
#for performing regex expressions
#for string tokens
exp = input()
source_code = exp.split() #turning source code into list of wom
# Loop through each source code word
for word in source_code:
#This will check if a token has datatype decleration
  if word in ['str', 'int', 'bool']:
    tokens.append(['DATATYPE', word])
  #This will look for an identifier which would be just a word 
  elif re.match("[a-z]", word) or re.match("[A-Z]", word): 
    tokens.append(['IDENTIFIER', word])
  #This will look for an operator
  elif word in '*-/+%=':
    tokens.append(['OPERATOR', word])
  #This will look for integer items and cast them as a number 
  elif re.match("[0-9]", word):
    if word[len(word) - 1] == ';':
        tokens.append(["INTEGER", word[:-1]])
        tokens.append(['END_STATEMENT', ';'])
    else:
      tokens.append(["INTEGER", word])

print(tokens)